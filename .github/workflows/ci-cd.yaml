name: Build and Deploy to K3s

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'backend/src/**'
      - 'backend/docker/**'
      - 'backend/k8s/**'
      - 'backend/requirements.txt'
      - '.github/workflows/ci-cd.yaml'
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:  # Ручной запуск

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  IMAGE_TAG: ${{ github.sha }}

jobs:
  # 1. Testing Job
  test:
    runs-on: ubuntu-latest
    name: Run Tests (Python ${{ matrix.python-version }})
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.12']
    permissions:
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
          pip install pytest pytest-cov pylint black flake8
          pip install -e backend/.
      
      - name: Run code quality checks
        run: |
          echo "Running Black formatter check..."
          black --check backend/src/ || true
          
          echo "Running Flake8 linter..."
          flake8 backend/src/ --max-line-length=100 --ignore=E501 || true
          
          echo "Running Pylint..."
          pylint backend/src/ --exit-zero || true
      
      - name: Run tests
        run: pytest backend/tests/ -v --cov=backend/src --cov-report=xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          fail_ci_if_error: false

  # 2. Build and Push Docker Image
  build:
    needs: test
    runs-on: ubuntu-latest
    name: Build Docker Image
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata (tags, labels) for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=raw,value=latest
            type=sha,prefix=,suffix=,format=short
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: ./backend
          file: ./backend/docker/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Verify image push
        run: |
          # Выводим все теги для отладки
          echo "Pushed tags:"
          echo "${{ steps.meta.outputs.tags }}"
          
          # Сохраняем теги в файл и читаем построчно для безопасной обработки
          echo "${{ steps.meta.outputs.tags }}" > tags_list.txt
          
          # Получаем список тегов и проверяем, что хотя бы один из них доступен
          while IFS= read -r tag; do
            # Пропускаем пустые строки
            [ -z "$tag" ] && continue
            
            echo "Checking if image exists: $tag"
            if docker manifest inspect "$tag" > /dev/null 2>&1; then
              echo "✓ Image exists: $tag"
            else
              echo "⚠ Image not accessible via docker manifest inspect: $tag"
            fi
          done < tags_list.txt

  # 3. Security Scanning
  security-scan:
    needs: build
    runs-on: ubuntu-latest
    name: Security Scanning
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set short SHA
        id: short_sha
        run: echo "sha7=${GITHUB_SHA:0:7}" >> $GITHUB_OUTPUT
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.29.0
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.short_sha.outputs.sha7 }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          timeout: '15m'
          exit-code: '0'
          skip-upload: false
      
      - name: Upload Trivy results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # 4. Deploy to K3s
  deploy:
    needs: [build, security-scan]
    runs-on: ubuntu-latest
    name: Deploy to K3s
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure kubeconfig
        env:
          KUBECONFIG_CONTENT: ${{ secrets.KUBECONFIG }}
        run: |
          mkdir -p $HOME/.kube
          echo "$KUBECONFIG_CONTENT" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
      
      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'
      
      - name: Create namespace
        run: |
          kubectl create namespace demo-app --dry-run=client -o yaml | kubectl apply -f -
      
      - name: Deploy Redis
        run: |
          echo "Deploying Redis..."
          # Развертываем Redis перед приложением
          if [ -f backend/k8s/redis.yaml ]; then
            kubectl apply -f backend/k8s/redis.yaml
            echo "Waiting for Redis to be ready..."
            kubectl wait --for=condition=ready pod -l app=demo-redis -n demo-app --timeout=3m || {
              echo "⚠️ Redis pod not ready, but continuing..."
              kubectl get pods -n demo-app -l app=demo-redis
            }
          else
            echo "⚠️ redis.yaml not found, Redis might be defined in deployment.yaml"
          fi
      
      - name: Verify image exists
        run: |
          SHORT_SHA=${GITHUB_SHA:0:7}
          IMAGE_TAG="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$SHORT_SHA"
          echo "Verifying image exists: $IMAGE_TAG"
          
          # Проверяем что образ доступен (используем docker manifest inspect через kubectl)
          if ! kubectl run image-checker --image=$IMAGE_TAG --rm -i --restart=Never --command -- echo "Image OK" 2>/dev/null; then
            echo "⚠️ Could not verify image via kubectl, but continuing deployment..."
          fi
      
      - name: Apply Kubernetes manifests
        run: |
          # Используем более простой и надежный подход
          # docker/metadata-action генерирует правильные теги
          SHORT_SHA=${GITHUB_SHA:0:7}
          IMAGE_FULL="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$SHORT_SHA"
          
          echo "Deploying with SHA: $SHORT_SHA"
          echo "Full image path: $IMAGE_FULL"
          
          # Проверяем текущий образ
          CURRENT_IMAGE=$(kubectl get deployment demo-app -n demo-app -o jsonpath='{.spec.template.spec.containers[0].image}' 2>/dev/null || echo "")
          echo "Current deployment image: $CURRENT_IMAGE"
          echo "New deployment image: $IMAGE_FULL"
          
          # Применяем deployment с заменой всех placeholders
          echo "Applying deployment-production.yaml with image replacement..."
          sed -e "s|IMAGE_REGISTRY|${{ env.REGISTRY }}|g" \
              -e "s|IMAGE_NAME|${{ env.IMAGE_NAME }}|g" \
              -e "s|IMAGE_TAG|$SHORT_SHA|g" \
              backend/k8s/deployment-production.yaml | kubectl apply -f -
          
          # Проверяем что образ правильно установлен после применения
          NEW_IMAGE=$(kubectl get deployment demo-app -n demo-app -o jsonpath='{.spec.template.spec.containers[0].image}' || echo "")
          echo "Deployment image after apply: $NEW_IMAGE"
          
          # Если образ не совпадает, устанавливаем его напрямую
          if [ "$NEW_IMAGE" != "$IMAGE_FULL" ]; then
            echo "⚠️ Deployment image ($NEW_IMAGE) doesn't match expected ($IMAGE_FULL)"
            echo "Setting image directly via kubectl set image..."
            kubectl set image deployment/demo-app -n demo-app app=$IMAGE_FULL || {
              echo "❌ Failed to set image directly"
              exit 1
            }
          fi
          
          # Принудительно обновляем deployment, если образ тот же (для перезапуска подов)
          if [ "$CURRENT_IMAGE" == "$IMAGE_FULL" ] && [ -n "$CURRENT_IMAGE" ]; then
            echo "⚠️ Image hasn't changed ($CURRENT_IMAGE), forcing rollout restart..."
            kubectl rollout restart deployment/demo-app -n demo-app
            echo "Waiting for restart to initiate..."
            sleep 5
          fi
          
          # Добавляем annotation с timestamp для принудительного обновления pod template
          TIMESTAMP=$(date +%s)
          kubectl annotate deployment demo-app -n demo-app \
            deployment.kubernetes.io/revision-history-limit=3 \
            kubectl.kubernetes.io/restartedAt="$TIMESTAMP" \
            --overwrite || true
          
          # Если после всех действий deployment не обновился, принудительно патчим pod template
          echo "Forcing pod template update..."
          kubectl patch deployment demo-app -n demo-app \
            -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"kubectl.kubernetes.io/restartedAt\":\"$TIMESTAMP\"}}}}}" \
            || true
          
          echo "✅ Kubernetes manifests applied successfully"
          
          # Apply ingress if it exists
          if [ -f backend/k8s/ingress.yaml ]; then
            kubectl apply -f backend/k8s/ingress.yaml
          fi
      
      - name: Wait for rollout
        run: |
          echo "=== Current deployment status ==="
          kubectl get deployment demo-app -n demo-app
          echo ""
          echo "=== Checking deployment rollout history ==="
          kubectl rollout history deployment/demo-app -n demo-app || true
          echo ""
          echo "=== Pods status before wait ==="
          kubectl get pods -n demo-app -l app=demo-app -o wide
          echo ""
          
          echo "=== Node resources and capacity ==="
          kubectl top nodes 2>/dev/null || echo "Metrics server not available"
          kubectl describe nodes | grep -A 10 "Allocated resources" || echo "Cannot get node resource allocation"
          echo ""
          
          echo "=== ReplicaSet status ==="
          kubectl get rs -n demo-app -l app=demo-app
          echo ""
          
          echo "=== Waiting for rollout (with periodic status checks) ==="
          
          # Запускаем rollout status в фоне и периодически проверяем статус
          timeout 360 kubectl rollout status deployment/demo-app \
            -n demo-app \
            --timeout=6m || {
            
            echo ""
            echo "❌ Rollout timeout, collecting detailed debug info..."
            echo ""
            
            echo "=== Deployment status ==="
            kubectl get deployment demo-app -n demo-app -o yaml | grep -A 20 "status:" || true
            echo ""
            
            echo "=== All pods detailed status ==="
            kubectl get pods -n demo-app -l app=demo-app -o wide
            echo ""
            
            echo "=== Deployment description ==="
            kubectl describe deployment demo-app -n demo-app
            echo ""
            
            echo "=== Pods detailed description ==="
            for pod in $(kubectl get pods -n demo-app -l app=demo-app -o jsonpath='{.items[*].metadata.name}'); do
              echo "--- Detailed info for pod $pod ---"
              kubectl describe pod $pod -n demo-app
              echo ""
              
              echo "--- Pod status for $pod ---"
              kubectl get pod $pod -n demo-app -o jsonpath='{.status}' | jq '.' || kubectl get pod $pod -n demo-app -o yaml
              echo ""
            done
            echo ""
            
            echo "=== Pod events (sorted by time) ==="
            kubectl get events -n demo-app --sort-by='.lastTimestamp' --field-selector involvedObject.kind=Pod | tail -30 || true
            echo ""
            
            echo "=== Pod logs (all containers) ==="
            for pod in $(kubectl get pods -n demo-app -l app=demo-app -o jsonpath='{.items[*].metadata.name}'); do
              echo "--- Logs for pod $pod (all containers) ---"
              kubectl logs $pod -n demo-app --all-containers=true --tail=50 || true
              echo ""
            done
            echo ""
            
            echo "=== Init container logs ==="
            for pod in $(kubectl get pods -n demo-app -l app=demo-app -o jsonpath='{.items[*].metadata.name}'); do
              echo "--- Init container logs for pod $pod ---"
              kubectl logs $pod -n demo-app -c wait-for-redis --tail=100 || echo "No init container logs for $pod"
              echo ""
            done
            echo ""
            
            echo "=== Resource usage ==="
            kubectl top pods -n demo-app 2>/dev/null || echo "Metrics server not available"
            echo ""
            
            echo "=== Redis status ==="
            kubectl get pods -n demo-app -l app=demo-redis || echo "Redis pods not found"
            kubectl get svc -n demo-app demo-redis || echo "Redis service not found"
            echo ""
            
            echo "=== ReplicaSet status ==="
            kubectl get rs -n demo-app -l app=demo-app
            echo ""
            
            echo "=== Checking for resource constraints ==="
            kubectl describe nodes | grep -A 5 "Allocated resources" || true
            echo ""
            
            exit 1
          }
          
          echo "✅ Rollout completed successfully!"
          echo ""
          echo "=== Final pods status ==="
          kubectl get pods -n demo-app -l app=demo-app -o wide
      
      - name: Rollback on failure
        if: failure()
        run: |
          echo "⏮️ Rolling back deployment..."
          kubectl rollout undo deployment/demo-app -n demo-app
          kubectl rollout status deployment/demo-app -n demo-app --timeout=5m
          echo "✅ Rollback completed"
      
      - name: Get deployment info
        run: |
          echo "=== Deployment Status ==="
          kubectl get deployment -n demo-app
          echo ""
          echo "=== Pods ==="
          kubectl get pods -n demo-app
          echo ""
          echo "=== Services ==="
          kubectl get svc -n demo-app
          echo ""
          echo "=== Ingress ==="
          kubectl get ingress -n demo-app
      
      - name: Check application health
        run: |
          echo "Checking application health..."
          
          # Проверяем что pods готовы
          echo "Waiting for pods to be ready..."
          kubectl wait --for=condition=ready pod -l app=demo-app -n demo-app --timeout=300s || {
            echo "❌ Pods failed to become ready"
            kubectl describe pods -n demo-app
            exit 1
          }
          
          # Тестируем через port-forward
          echo "Port-forwarding to service..."
          kubectl port-forward -n demo-app svc/demo-app 8080:80 > /dev/null 2>&1 &
          PF_PID=$!
          sleep 5  # Увеличиваем время ожидания до 5 секунд
          
          # Проверяем, что port-forward запущен
          timeout 10 sh -c 'until nc -z localhost 8080; do sleep 1; done' || {
            echo "❌ Port-forward failed to start"
            exit 1
          }
          
          for i in {1..15}; do
            echo "Health check attempt $i/15..."
            if curl -f -s -m 5 http://localhost:8080/api/health > /dev/null 2>&1; then
              echo "✅ Application is healthy"
              kill $PF_PID 2>/dev/null || true
              exit 0
            fi
            echo "⏳ Waiting for application to be ready..."
            sleep 3
          done
          
          echo "❌ Application health check failed after 15 attempts"
          echo "Pod logs:"
          kubectl logs -n demo-app --all-containers=true --tail=50
          kill $PF_PID 2>/dev/null || true
          exit 1

  # 5. Post-Deployment Checks
  post-deploy:
    needs: deploy
    runs-on: ubuntu-latest
    name: Post-Deployment Verification
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure kubeconfig
        env:
          KUBECONFIG_CONTENT: ${{ secrets.KUBECONFIG }}
        run: |
          mkdir -p $HOME/.kube
          echo "$KUBECONFIG_CONTENT" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
      
      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'
      
      - name: Run integration tests
        run: |
          # Change to backend directory
          cd backend
          
          # Проверяем что приложение запущено и отвечает
          kubectl get pods -n demo-app
          
          # Получаем имя одного из pod'ов приложения
          POD_NAME=$(kubectl get pods -n demo-app -l app=demo-app -o jsonpath='{.items[0].metadata.name}')
          
          # Устанавливаем curl в pod, если его нет
          kubectl exec -n demo-app $POD_NAME -- which curl || kubectl exec -n demo-app $POD_NAME -- apk add --no-cache curl
          
          # Проверяем health endpoint
          kubectl exec -n demo-app $POD_NAME -- curl -s 'http://localhost:5000/api/health'
          
          # Проверяем info endpoint
          kubectl exec -n demo-app $POD_NAME -- curl -s 'http://localhost:5000/api/info'
          
          # Проверяем ping endpoint
          kubectl exec -n demo-app $POD_NAME -- curl -s 'http://localhost:5000/api/ping'
      
      - name: Check pod logs
        if: always()
        run: |
          echo "=== Recent Pod Logs ==="
          kubectl logs -n demo-app -l app=demo-app --tail=50 || true
      


